 ### 在后台线程中渲染
  GLSurfaceView 会在一个单独的线程中调用渲染器的方法，GLSurfaceView会以显示设备的刷新频率不断的进行渲染，
  只要用GLSurfaceView.RENDERMODE_WHEN_DIRTY作为参数调用GLSurfaceView.setRenderMode()


  思考： 既然Android的GLSurfaceView在后台线程中执行渲染，只能在这个渲染线程中调用OpenGL，在Android主线程中
  使用UI（用户界面）相关调用。这就涉及了主线程和子线程的交互问题。

  Handler+Message 的操作。


  在主线程中的GLSurfaceView实例可以调用queueEvent() 方法传递一个Runnable给后台渲染线程。
  渲染线程可以调用Activity的runOnUIThread()来传递事件给主线程。


 ## 绘制顶点
    三角形的卷曲顺序，总是以逆时针的顺序(0,0) -> (9,0)->(9,14),总是以逆时针的顺序排列的顶点，就称为卷曲顺序，

    在任何地方都使用这种一致的卷曲顺序，可以优化性能。

   (0,14) ------------(9,14)
   |                 /  |
   |                /   |
   |               /    |
   |              /     |
   |             /      |
   |            /       |
   |           /        |
   |          /         |
   |         /          |
   |        /           |
   |       /            |
   |      /             |
   |     /              |
   |    /               |
   |   /                |
   (0,0)---------------(9,0)


  ### OpenGL如何读取Java层数据：

    1。 当我们在设备上编译和运行java代码的时候，并不能直接运行硬件上的，相反，运行在一个特俗的环境上，
        即Dalvik虚拟机上，运行在虚拟机上的代码不能直接访问本地环境（native env）《用户空间和内核空间》

    2。Davik虚拟机还是使用了垃圾回收机制，意味着当虚拟机检测一个变量，对象或者其他内存片段不再被使用时，就会把这些内存释放掉，
       提高空间使用效率

    那么本地环境并不是这样工作的，内存块并不会被自动释放，OpenGl作为本地系统库直接运行在硬件上，
    没有虚拟机，也没有垃圾回收或内存压缩。

    数据交互方案：
    1。从Java调用本地代码（JNI技术方案）
    2。把内存从Java堆复制到本地堆
        Java有一个特殊的类集合，可以分配本地内存块，并且把Java的数据复制到本地内存，本地内存可以被本地环境存取，而不受垃圾回收器的管控。


       ```
           float[] tableVerticesWithTriangle={
                //triangle1
                0f,0f,
                9f,14f,
                0f,14f,

                //triangle2
                0f,0f,
                9f,0f,
                9f,14f,

            };
            FloatBuffer vertexData = ByteBuffer
                         .allocateDirect(tableVerticesWithTriangle.length*4) //1
                         .order()//2
                         .asFloatBuffer();//3
             vertexData.put(tableVerticesWithTriangle);//4

            //1 分配一块本地内存，这块内存不会被垃圾回收器管理，需要知道分配多少字节的内存块，因为顶点都存储在一个浮点数组中，
            //并且每个浮点数都有4个字节，所以这块内存的大小为数组长度*4

            //2 告诉字节缓冲区按照本地字节序组织它的内容，本地字节序：当一个值占用多个字节，比如32位整型数，字节按照从最重要到
            //最不重要位或者相反顺序排列，可以认为从左到右或者从右到左写一个数类似，其实排序并不重要，重要是一个平台都使用同样的顺序，
            调用order(ByteOrder.nativeOrder()) 可以保证这一点

            //3 调用asFloatBuffer 可以得到一个可以反映底层字节的FloatBuffer类实例，
            //4 调用put() 把数据从Dalvik的内存复制到本地内存中。当进程结束之后，这块内存就会被释放，
       ```


     ## OpenGl管道的概念

         定义了三角形的结构（顶点坐标）并且把数据复制到了OpenGL可以存取的本地内存，那么三角形画到屏幕上之前
         需要在OpenGl的管道中传递。这就需要着色器的子例程，这些着色器会告诉GPU如何绘制数据，

         有两种类型着色器，在绘制内容到屏幕之前，需要定义他们。

       1。顶点着色器（vertex shader）：生成每个顶点的最终位置，针对每个顶点，它都会执行一次，
          一旦最终位置确定了，OpenGL就可以把这些可见顶点的集合组装成点，线以及三角形，
       2。片段着色器（fragment shader）：为组成点，直线或者三角形的每个片段生成最终的颜色，针对每一个片段，
          都会执行一次，一个片段是一个小的，单一颜色的长方形区域，类似计算机屏幕上的一个像素。


        一旦最后的颜色生成了，OpenGl就会把他们写到一块称为帧缓冲区（frame buffer)的内存块，然后Android会把
        这个帧缓冲区显示到屏幕上，

        读取顶点数据 -- 》 执行顶点着色器程序----- 》组装图元（点，直线，三角形）-----》光栅化图元（？？）----》执行片段着色器程序----》写入帧缓冲区------》显示在屏幕上

        ```
            attribute vec4 a_Position;

            void main(){

              gl_Position = a_Position;
            }
        ```
        vec4包含4个分量的向量，x，y，z，w坐标，x，y，z对一个三维坐标，w是一个特殊的坐标。
        "attribute"就是把这些位置 颜色信息放进着色器的手段；

        main() 就是着色器的主要入口，所做的就是把之前定义的位置信息复制到指定的输出变量gl_Position；
        那么OpenGL会把gl_Position 中存储的值作为当前顶点的最终位置。
        并把这些顶点组装成点，直线和三角形

        ```
            precision mediump float;

            uniform vec4 u_Color;

            void main(){
               gl_FragColor=u_Color;
            }
        ```
        片段着色器主要目的就是告诉GPU每个片段最终的颜色是什么，对于基本图元（点，直线，三角形）的每个片段，片段着色器都会被调用一次，

        精度限定符： lowp，mediump，highp；why？
                    顶点着色器同样可以改变其默认的精度，但是对于一个顶点的位置而言，精确到是最重要的，因此顶点着色器的精度默认是最高highp；
                    片段着色器选择mediump，是基于速度和质量的权衡，高精度是会降低性能的。
        uniform 不像属性，每个顶点都有设置一个，一个uniform会让每个顶点都使用同一个值，除非再次改变它，
        main() 把u_Color赋值给特殊的输出变量gl_FragColor ，着色器一定要给gl_FragColor赋值。OpenGl会使用这个颜色作为当前片段的最终颜色。


        1。读取shader字符串
        2。创建着色器对象，glCreateShader(int type);
        3. 加载着色器源码到着色器对象，glShaderSource(int shaderId,String sourcecode);
        4. 编译着色器代码  glCompileShader(shaderId);
        5. 获取编译状态 glGetShaderiv(int shaderId,GL_COMPILE_STATUS,int status,int offset);
        6. 失败删除shader glDeleteShader(shaderId);
        7. 成功返回shaderId;


        .... OpenGL程序：就是把一个顶点着色器和一个片段着色器链接在一起变成单个对象，
        .... 顶点着色器和片段器总是一起工作的。虽然顶点着色器和片段着色器总是要一起工作，但是并不意味着他们必须一对一匹配，可以同时多个程序使用同一个着色器

        1.新建程序对象 glCreateProgram();
        2.将着色器依附到程序对象上，glAttachShader(programId,vertexShaderId);
                                glAttachShader(programId,fragmentShaderId);

        3.链接程序 glLinkProgram(programId);
        4.检查链接状态，glGetProgramiv(programId,GL_LINK_STATUS,int status,int offset);
        5.失败删除程序 glDeleteProgram(programId);
        6.成功返回programId;




     ### 三角形扇
       为了是中间更加明亮，其他边缘比较暗淡，我们就需要将颜色变量以属性的形式提供，而不是
       通过unifrom的单一颜色形式进行绘制。因此做的第一件事情就是在中间引入了一个点（0，0）
       此时好像是4个三角形，是不是就需要3*4=12点来构建这个矩形。


       但是我们引入三角形扇就不需要这么多点了，

       中心点被四个三角形使用了，那么就不得不一次又一次的输入同一个坐标
       可以以一个中心点为起始点，使用相邻的两个顶点创建第一个三角形，


          《5》(0,14)-----------(9,14)《4》
               | \               /|
               |  \             / |
               |   \ 5         /  |
               |    \         /   |
               |     \       /    |
               |      \     /     |
               |       \   /      |
               |        \ /       |
               |     (0,0) <1>    |
               |        / \       |
               |       /   \      |
               |      /     \     |
               |     /       \    |
               |    /         \   |
               |   /           \  |
           <2>(0,0)------------(9,0)《3》


        ### 适配宽高比：

            横竖屏切换的时候，宽高比发生改变了，之前竖屏的宽高比是720/1280
            那么如果切换为横屏，宽高比就变成了1280/720

            如果没有进行处理，图像就可能被压扁。横屏的时候，

            在Opengl，要渲染的一切物体都映射到了x轴和y轴上[-1,1]的范围内。
            对于z轴也一样。


            那么这个范围呢的坐标就被称为归一化设备坐标。
            独立于设备的尺寸 形状。


            那么如何适应宽高比呢？

            可行的办法就是不是把较小的范围固定在[-1,1]，
                        而是按照屏幕尺寸的比例调整较大的范围

            举例：竖屏情况下，width 720 height 1280
                                                  宽度可以限定在[-1,1]
                                                  高度范围调整为[-1280/720,1280/720]
                 横屏情况下。width 1280 height 720
                                                 高度可以限定在[-1,1]
                                                 宽度范围调整为[-1280/720,1280/720]

            使用虚拟空间，我们需要把调整坐标空间，将虚拟空间投影到归一化坐标上。
            这需要用到正交投影， 使用了正交投影，不管多远多近，所有物体看上去大小总是相同的。
            虚拟空间 类比我们一个三维空间，物体所处的位置坐标就是处理三维空间的坐标。
            我们干的事情就是把三维空间的坐标投影到归一化坐标上来。
            手段就是通过正交投影，

            /**
             * m: 目标数组，至少16个元素，存储正交投影矩阵
             * offset:结果矩阵起始的偏移量
             * left：x轴的最小范围（-1或者是-w/h，-h/w ）
             * right：x轴的最大范围（1或者是w/h，h/w ）
             * bottom：y轴的最小范围（-1或者是-w/h，-h/w ）
             * top：y轴的最大范围（1或者是w/h，h/w ）
             * near：z轴最小范围（-1）
             * far：z轴最大范围（1）
             */
            orthoM(float[] m, int mOffset,
                           float left, float right, float bottom, float top,
                           float near, float far)；
             _                                                                 _
            |                                                                   |
            |  2/right-left      0            0        -(right+left/right-left) |
            |                                                                   |
            |                                                                   |
            |     0        2/top-bottom       0        -(top+bottom)/top-bottom |
            |                                                                   |
            |     0              0        -2/far-near     -(far+near)/far-near  |
            |                                                                   |
            |     0              0            0                    1            |
            |                                                                   |
             _                                                                 _


         ## 三维模式的引入

            1。OpenGL的透视除法的概念
            2。w分量创造三维

            - 着色器到屏幕的坐标变换

               归一化设备坐标（正交投影） x，y，z分量都要在【-1，1】内取值，
               gl_Position ->透视除法-->归一化设备坐标--->视口变换--->窗口坐标

              剪裁空间：当顶点着色器把一个值写到gl_Position的时候，OpenGl希望对于任何给定的位置，x，y，z分量都在那个位置的-w 和 w之间，任何这个范围外的事物在屏幕上都是不可见的。


              透视除法：为了在屏幕上创建三维幻象，gl_Position的x，y，z分量都除以它的w分量，
              当w分量用来表示距离的时候，
              就使得较远处的物体被移动到距离渲染区域的中心点更近的地方，
              也就是肉眼看不到的地方（好比宇宙中心点）消失点


              z分量作为深度缓冲区

              除以w分量解耦合实际的z坐标，方便在正交投影和透视投影之间切换。


             视口变换； opengl需要把归一化设备坐标的x和y分量映射到屏幕上的一个区域，这个区域就是视口。

             从例子看到，加入了w分量，OpenGl为我们做了透视除法来达到一种立体效果，但是这是一种硬编码方式，
             如果想要动态实现这种效果，就需要用到矩阵。



     ## 定义透视投影

        投影矩阵不能自己做透视除法，而透视除法需要w分量才能起到作用。
        如果一个物体向屏幕中心移动，当它离我们越来越远时，它的大小就越来越小，因此
        投影矩阵最重要的任务就是为w产生正确的值，当OpenGL做透视除法的时候，远处的物体看起来就会比近处的小，
        那么实现这些方法之一利用z分量，把它作为物体于焦点的距离并且把这个距离映射到w，这个距离越大，w值就越大，所得物体就越小。



       通用的投影矩阵：

       ｜ a/aspect   0        0           0    ｜
       ｜ 0          a        0           0    ｜
       ｜ 0          0     -f+n/f-n    -2fn/f-n｜
       ｜ 0          0        -1          0    ｜

        a:相机的焦距  1/tan(视野/2） 视野必须小于180度， 一个90度的视野，焦距被设置为1/tan(90/2) =1/1=1
        aspect:屏幕的宽高比，宽度/高度
        f：到远处平面的距离，必须是正值且大于到近平面的距离
        n：到近平面的距离，必须是正值，如果此值设置为1，那近平面就位于一个z值为-1处


     ## 模型矩阵
        进行平移操作 把视图移动到投影矩阵设置的范围之内。
        float[] modelMatrix =new float[16];

        Matrix.setIdentity(modelMatrix,0);
        Matrix.translateM(modelMatrix,0,0f,0f,-2f);
        把模型矩阵设置为单位矩阵，然后沿着z轴平移-2；

     ##投影矩阵*模型矩阵

       vertex = projectMatrix*ModelMatrix*vertexmodel

       旋转矩阵
       rotateM(modelMatrix,0,-60f,1,0,0):
       表示将modelMatrix按照x轴方向逆时针旋转60度




     ## 理解纹理

       纹理可以用来表示图像，照片，甚至由一个数学算法生成的分形数据，每个二维的纹理都由许多个小的纹理元素组成，小块的数据，


       纹理的坐标空间 范围 （0，0） -- （1，1）

       图像的默认方向，y轴向下，y的值随着向图像的底部移动而增加，


       把纹理加载进入OpenGL

       1.将图像文件的数据加载到一个openGl的纹理中，
      final int[] textureId =new int[1];

       glGenTextures(1,textureId,0);

       2.加载位图数据并与纹理绑定

        BitmapFactory.Options options =new BitmapFactory.Options();
        options.inScaled=false; //原始数据

        Bitmap bitmap =BitmapFactory.decodeResource(context.getResource(),resourceId);
        if(bitmap==null){
            //位图加载失败
            glDeleteTextures(1,textureId,0);
            return 0;
        }
        glBindTexture(GL_TEXTURE_2D,textureId[0]);

        3.设置纹理过滤：当纹理大小被扩大或者缩小时候，需要使用纹理过滤说明会发生什么，最近邻过滤，双线性过滤（平滑，抗锯齿）mip贴图

        glTexParameteri(GL_TEXTURE_2D,GL_TEXTURE_MIN_FILTER,GL_LINEAR_MIPMAP_LINEAR);
        glTexParameteri(GL_TEXTURE_2D,GL_TEXTURE_MAG_FILTER,GL_LINEAR);

        4.加载纹理到OpenGl并返回ID
           //告诉OpenGL读取bitmap定义的位图数据，并把它复制到当前绑定的纹理对象
           texImage2D(GL_TEXTURE_2D,0,bitmap,0);
           bitmap.recycle();//数据已经加载到了OpenGl中，应该调用bitmap对象的recycle方法进行数据的释放

        5.完成纹理的加载，就需要解除与这个纹理的绑定，这样就不会用其他的纹理方法调用改变这个纹理
        glBindTexture(GL_TEXTURE_2D,0);

        6.返回纹理ID
            return textureId[0];



        创建新的着色器集合 （与纹理相关）

        顶点着色器

        uniform mat4 u_Matrix;

        attribute vec4 a_Position;
        attribute vec2 a_TextureCoordinates;

        varying    vec2 v_TextureCoordinates;

        void main(){
            v_TextureCoordinates = a_TextureCoordinates;
            gl_Position =u_Matrix*a_Position;
        }
        纹理坐标 a_TextureCoordinates 两个分量S T


        片段着色器
        precision mediump float;

        uniform sampler2D u_TextureUnit;

        varying vec2 v_TextureCoordinates;

        void main(){
            gl_FragColor=texture2D(u_TextUnit,v_TextureCoordinates);
        }
        //sample 错误的
        //sampler2D正确的。
        sampler2D : 这个变量类型指的是一个二维纹理数据的数组，接收纹理坐标（数据）
        v_TextureCoordinates:代表每一个纹理坐标点，刚好把这些坐标点加到一个sample2D的数组里面，
        texture2D：读入纹理中那个特定坐标处的颜色值。接着通过把结果赋值给
        gl_FragColor,这样就可以设置片段的颜色了。














